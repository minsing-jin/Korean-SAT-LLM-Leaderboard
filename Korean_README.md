![image](https://github.com/user-attachments/assets/f9d08905-33fe-48c0-a540-6b25c7e64563)

# ğŸ† KO-SAT Slayer Champions League

**KO-SAT Slayer Champions League**ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! í•œêµ­ ìˆ˜ëŠ¥(SAT) ìµœê³ ì˜ slayerë¥¼ ê°€ë¦¬ê¸° ìœ„í•œ ë¦¬ë”ë³´ë“œì…ë‹ˆë‹¤! ğŸš€

ì—¬ëŸ¬ë¶„ì˜ í•œêµ­ì–´ LLM finetuning ëª¨ë¸ì´ í•œêµ­ ìˆ˜ëŠ¥ 10ê°œë…„ benchmarkì—ì„œëŠ” ëª‡ì ì´ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”!

GPU ìì›ì„ ì œê³µí•´ì£¼ì‹ ë‹¤ë©´ í‰ê°€ì— í° ë„ì›€ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!

## ğŸ¯ KO-SAT Slayer Champions League Leaderboardë€?

KO-SAT Slayer Champions LeagueëŠ” í•œêµ­ì˜ ê³µì‹ ë ¥ ìˆëŠ” ë§¤ì²´ì¸ KICE(í•œêµ­êµìœ¡ê³¼ì •í‰ê°€ì›)ì—ì„œ ê°œë°œí•œ ëŒ€í•™ìˆ˜í•™ëŠ¥ë ¥í‰ê°€ ì‹œí—˜ì¸ êµ­ì–´ 10ê°œë…„ ì‹œí—˜ë¬¸ì œë¥¼ benchmarkí•œ ë¦¬ë”ë³´ë“œì…ë‹ˆë‹¤.
ìˆ˜ëŠ¥ ë¬¸ì œëŠ” ë‚œì´ë„ì— ë”°ë¼ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ë…í•´ë ¥, ë¹„íŒì  ì‚¬ê³ , ë¬¸ì¥ í•´ì„ ëŠ¥ë ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

## ğŸ† ëª…ì˜ˆì˜ ì „ë‹¹

- **Rank ê¸°ì¤€**: 10ê°œë…„ ìˆ˜ëŠ¥ í‘œì¤€ì ìˆ˜ë“¤ì˜ í‰ê·  (í‘œì¤€ì ìˆ˜ë¥¼ í†µí•´ì„œ ê° ë…„ë„ë³„ ì‹œí—˜ì˜ ë‚œì´ë„ë¥¼ ì ìˆ˜ì—ì„œ ë°˜ì˜í•©ë‹ˆë‹¤.)
- **ìˆ˜ëŠ¥ ì ìˆ˜ í‘œê¸°**: ì›ì ìˆ˜(ë“±ê¸‰)

[ì ìˆ˜ì— ëŒ€í•œ ì„¤ëª… ë°”ë¡œê°€ê¸°](https://github.com/minsing-jin/KO-SAT_Slayer_Champions_League/blob/main/Korean_README.md#%EF%B8%8F-metric)

| Leaderboard Rank | Model Name                         | Submitter Name | Avg. Korean SAT std Score (2015-2024) | Avg. Korean SAT Raw Score (2015-2024) | Avg. Grade | 2015 SAT | 2016 SAT | 2017 SAT | 2018 SAT | 2019 SAT | 2020 SAT | 2021 SAT | 2022 SAT | 2023 SAT | 2024 SAT | URL                                                                                                                                    |
|-----------------:|:-----------------------------------|:---------------|--------------------------------------:|--------------------------------------:|-----------:|:---------|:---------|:---------|:---------|:---------|:---------|:---------|:---------|:---------|:---------|:---------------------------------------------------------------------------------------------------------------------------------------|
|           ğŸ¥‡ 1st | gpt-4o                             | OpenAI         |                                 114.9 |                                  75.9 |        3.6 | 77 (4)   | 84 (3)   | 86 (2)   | 77 (4)   | 74 (3)   | 76 (4)   | 69 (4)   | 70 (4)   | 81 (4)   | 65 (4)   | [Link](https://openai.com/)                                                                                                            |
|           ğŸ¥ˆ 2nd | Meta-Llama-3.1-405B-Instruct-Turbo | meta-llama     |                                 113.8 |                                  74.9 |        3.8 | 68 (5)   | 87 (3)   | 80 (3)   | 78 (4)   | 68 (4)   | 65 (5)   | 70 (4)   | 69 (4)   | 87 (3)   | 77 (3)   | [Link](https://huggingface.co/meta-llama/Llama-3.1-405B-Instruct)                                                                      |
|           ğŸ¥‰ 3rd | Meta-Llama-3.1-70B-Instruct-Turbo  | meta-llama     |                                 103.7 |                                  65.1 |        4.8 | 70 (5)   | 71 (5)   | 66 (5)   | 58 (6)   | 51 (5)   | 79 (3)   | 61 (5)   | 73 (3)   | 72 (5)   | 50 (6)   | [Link](https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct)                                                                       |
|              4th | Qwen2-72B-Instruct                 | Qwen           |                                    98 |                                  59.3 |        5.2 | 63 (5)   | 58 (6)   | 69 (5)   | 76 (4)   | 56 (5)   | 57 (5)   | 45 (6)   | 59 (5)   | 57 (6)   | 53 (5)   | [Link](https://huggingface.co/Qwen)                                                                                                    |
|              5th | gpt-4o-mini                        | OpenAI         |                                  93.9 |                                  55.2 |        5.6 | 57 (6)   | 64 (5)   | 58 (6)   | 62 (5)   | 46 (6)   | 50 (6)   | 55 (5)   | 50 (6)   | 53 (6)   | 57 (5)   | [Link](https://openai.com/)                                                                                                            |
|              6th | gemma-2-27b-it                     | Google         |                                    91 |                                  52.5 |        5.9 | 56 (6)   | 54 (6)   | 71 (4)   | 50 (6)   | 37 (7)   | 50 (6)   | 51 (6)   | 51 (6)   | 54 (6)   | 51 (6)   | [Link](https://huggingface.co/google/gemma-2-27b-it)                                                                                   |
|              7th | solar-mini-ja                      | Upstage        |                                  85.9 |                                  47.4 |        6.2 | 52 (6)   | 40 (7)   | 48 (7)   | 49 (6)   | 51 (5)   | 46 (6)   | 41 (7)   | 43 (6)   | 58 (6)   | 46 (6)   | [Link](https://ko.upstage.ai/feed/company/event-recap-exploring-japan-ai-scene-with-upstage-solar-mini-ja)                             |
|              8th | solar-mini                         | Upstage        |                                  85.5 |                                  47.2 |        6.4 | 56 (6)   | 42 (7)   | 55 (6)   | 43 (7)   | 50 (6)   | 46 (6)   | 42 (7)   | 48 (6)   | 57 (6)   | 33 (7)   | [Link](https://www.upstage.ai/feed/product/solarmini-performance-report)                                                               |
|              9th | Mixtral-8x22B-Instruct-v0.1        | MistralAI      |                                  83.4 |                                  45.1 |        6.6 | 44 (7)   | 50 (6)   | 57 (6)   | 65 (5)   | 35 (7)   | 38 (7)   | 31 (8)   | 47 (6)   | 44 (7)   | 40 (7)   | [Link](https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1)                                                                   |
|             10th | WizardLM-2-8x22B                   | Microsoft      |                                  83.3 |                                  45.3 |        6.6 | 53 (6)   | 51 (6)   | 47 (7)   | 51 (6)   | 29 (8)   | 52 (6)   | 30 (8)   | 47 (6)   | 56 (6)   | 37 (7)   | [Link](https://www.microsoft.com/en-us/research/publication/wizardlm-empowering-large-language-models-to-follow-complex-instructions/) |
|             11th | Meta-Llama-3.1-8B-Instruct-Turbo   | meta-llama     |                                  74.7 |                                  36.5 |        7.1 | 45 (7)   | 37 (7)   | 38 (7)   | 38 (7)   | 24 (8)   | 36 (7)   | 34 (7)   | 36 (7)   | 31 (8)   | 46 (6)   | [Link](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct)                                                                        |
|             12th | gpt-3_5-turbo                      | OpenAI         |                                  68.7 |                                  30.6 |        7.7 | 27 (8)   | 45 (7)   | 25 (8)   | 38 (7)   | 24 (8)   | 36 (7)   | 17 (9)   | 26 (8)   | 39 (7)   | 29 (8)   | [Link](https://openai.com/)                                                                                                            |
|             13th | Mixtral-8x7B-Instruct-v0.1         | MistralAI      |                                  63.4 |                                  25.2 |        8.3 | 19 (9)   | 30 (8)   | 16 (9)   | 37 (7)   | 19 (9)   | 27 (8)   | 20 (9)   | 40 (7)   | 25 (8)   | 19 (9)   | [Link](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)                                                                    |
|             14th | gemma-2-9b-it                      | Google         |                                  61.2 |                                  23.1 |        8.4 | 29 (8)   | 25 (8)   | 25 (8)   | 24 (8)   | 29 (8)   | 17 (9)   | 22 (9)   | 16 (9)   | 20 (9)   | 24 (8)   | [Link](https://huggingface.co/google/gemma-2-9b-it)                                                                                    |
|             15th | Llama-3.2-3B-Instruct-Turbo        | meta-llama     |                                  60.6 |                                  22.4 |        8.7 | 23 (9)   | 22 (9)   | 29 (8)   | 21 (9)   | 17 (9)   | 16 (9)   | 23 (9)   | 27 (8)   | 18 (9)   | 28 (8)   | [Link](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)                                                                        |
|             16th | Mistral-7B-Instruct-v0.3           | MistralAI      |                                  57.2 |                                  19.1 |        8.9 | 21 (9)   | 23 (9)   | 27 (8)   | 19 (9)   | 21 (9)   | 18 (9)   | 12 (9)   | 22 (9)   | 11 (9)   | 17 (9)   | [Link](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)                                                                      |

### ğŸ“— Notes. 24 ìˆ˜ëŠ¥ (1ê°œë…„) ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼

- **o1-preview**: 88ì  (1ë“±ê¸‰, ìƒìœ„ 4%)
- **o1-mini** : 60ì  (5ë“±ê¸‰)


## ğŸ… Submit ë°©ì‹

- ë¦¬ë”ë³´ë“œ ê³µê°œë¥¼ ì›í•˜ì§€ ì•Šê³ , privateí•˜ê²Œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì•Œê³  ì‹¶ë‹¤ë©´ í•˜ê³  ì‹¶ì€ ë§ íŒŒíŠ¸ì— ë‚¨ê²¨ì£¼ì„¸ìš”!
- â­ï¸ ìˆ˜ëŠ¥ ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•œ ëª¨ë¸ì˜ context lengthëŠ” ìµœì†Œ 8K ì´ìƒì´ì–´ì•¼í•©ë‹ˆë‹¤! 

1. **ëª¨ë¸ submission**:
    - **[ì„¤ë¬¸ Formìœ¼ë¡œ ì œì¶œ](https://moaform.com/q/QP0AV0)**: ì„¤ë¬¸ ì‘ë‹µì— ë§ì¶° ì‘ì„±í•´ì£¼ì„¸ìš”!
        - ë§í¬: https://moaform.com/q/QP0AV0
    - **ì´ë©”ì¼ë¡œ ì œì¶œ**: huggingFaceì— ê²Œì‹œëœ ìì‹ ì˜ finetuning ëª¨ë¸ì˜ Urlê³¼ ë‹‰ë„¤ì„ì„ ì „ì†¡í•´ì£¼ì„¸ìš”!
        - ì œì¶œ ë©”ì¼: developerminsing@gmail.com
    - **issueë¡œ ì œì¶œ**: Githubì˜ ì´ìŠˆì—ì„œ ìì‹ ì˜ finetuning ëª¨ë¸ì˜ Urlê³¼ ë‹‰ë„¤ì„ì„ ê²Œì‹œí•´ì£¼ì„¸ìš”!
    ```markdown
   <ì´ë©”ì¼ ì œì¶œ, ì´ìŠˆ ì œì¶œì‹œ Form example>
    ì œì¶œì ì´ë¦„: ê°ìŠ¤íŠ¸
    HuggingFace ì œì¶œ URL: https://huggingface.co/ê°ìŠ¤íŠ¸ëª¨ë¸ì§œìŠ¤
    í•˜ê³  ì‹¶ì€ë§: ì—´ì‹¬íˆ í•˜ì‹œì–ì•„
    ```

2. **ë¦¬ë”ë³´ë“œ í™•ì¸**: githubì™€ huggingFaceì—ì„œ ìì‹ ì˜ ìˆœìœ„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **ìˆœìœ„ ìƒìŠ¹ ë„ì „**: ìì‹ ì˜ ìˆœìœ„ë¥¼ ì˜¬ë ¤ **Slayer Champion** íƒ€ì´í‹€ì„ íšë“í•˜ì„¸ìš”.

**Notice:** ëª¨ë¸ ì œì¶œí›„ ê°€ìš©í•œ GPU ë¦¬ì†ŒìŠ¤ì™€, ì œì¶œëŸ‰ì— ë”°ë¼ 1~3ì£¼ì¼ì˜ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸª‘ Benchmark ë°ì´í„°ì…‹

- ë³¸ ëŒ€íšŒì—ì„œëŠ” 2015ë…„ë¶€í„° 2024ë…„ê¹Œì§€ì˜ 10ê°œë…„ ìˆ˜ëŠ¥ êµ­ì–´ ë¬¸ì œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê° ë…„ë„ì˜ ìˆ˜ëŠ¥ êµ­ì–´ ì‹œí—˜ì—ì„œ ì¶œì œëœ ë¬¸ì œì™€ ì§€ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€íšŒ ì°¸ê°€ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê²Œ ë©ë‹ˆë‹¤.
  ìˆ˜ëŠ¥ ë¬¸ì œëŠ” ë‚œì´ë„ì— ë”°ë¼ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ë…í•´ë ¥, ë¹„íŒì  ì‚¬ê³ , ë¬¸ì¥ í•´ì„ ëŠ¥ë ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

- Benchmark ë°ì´í„°ì…‹ì˜ ì£¼ìš” í‰ê°€ ëª©ë¡ì€ ì–¸ì–´ ì´í•´ë ¥, í•µì‹¬ ë‚´ìš© íŒŒì•… ëŠ¥ë ¥, ë…¼ë¦¬ì  ì‚¬ê³ ë ¥, ë¹„íŒì  ì‚¬ê³ ë ¥, ì°½ì˜ì  ì‚¬ê³ ë ¥, ë©€í‹°ë¯¸ë””ì–´ í•´ì„ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
  <ì¶œì²˜: 2024 KICE ìˆ˜ëŠ¥ êµ­ì–´ í‰ê°€ ëª©ë¡>

## â™¾ï¸ Metric

### í‰ê°€ ë°©ì‹
- ëŒ€íšŒì—ì„œëŠ” ê° ëª¨ë¸ì´ ì œì‹œëœ ë¬¸ì œì— ëŒ€í•´ ì œì¶œí•œ ë‹µì•ˆì´ ì‹¤ì œ ì •ë‹µê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ì¸¡ì •í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
- í‰ê°€ ì ìˆ˜ëŠ” ê° ë…„ë„ì˜ ë¬¸ì œë³„ë¡œ ì±„ì ë˜ë©°, ìµœì¢…ì ìœ¼ë¡œëŠ” í‘œì¤€ì ìˆ˜ì˜ í‰ê· ì„ í†µí•´ ìˆœìœ„ê°€ ë§¤ê²¨ì§‘ë‹ˆë‹¤.

### ë¦¬ë”ë³´ë“œ ì ìˆ˜ ì„¤ëª…
- **ì›ì ìˆ˜ë€?**: ì‹œí—˜ì—ì„œ 100ì ë§Œì ìœ¼ë¡œ ë°›ì€ ì ìˆ˜
- **í‘œì¤€ì ìˆ˜**: ì‘ì‹œìƒì´ ë°›ì€ ì›ì ìˆ˜ê°€ í‰ê· ì—ì„œ ì–¼ë§ˆë‚˜ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ ì¼ì¢…ì˜ 'í‰ê· ê³¼ì˜ ê±°ë¦¬'ë¥¼ ì¸¡ì •í•˜ëŠ” ì ìˆ˜
- **ë“±ê¸‰**: í‘œì¤€ì ìˆ˜ì— ê·¼ê±°í•´ ìˆ˜í—˜ìƒì„ ë‚˜ëˆˆ ê²ƒìœ¼ë¡œ, ì´ 9ë“±ê¸‰ì´ ìˆë‹¤. êµ­ì–´ì™€ ìˆ˜í•™, íƒêµ¬ì˜ì—­ì—ì„œëŠ” ì˜ì—­ê³¼ëª©ë³„ ì „ì²´ ìˆ˜í—˜ìƒì˜ ìƒìœ„ 4%ê°€ 1ë“±ê¸‰, ê·¸ë‹¤ìŒ 7%(ëˆ„ì  11%)ê¹Œì§€ê°€ 2ë“±ê¸‰, ê·¸ë‹¤ìŒ 12%(ëˆ„ì  23%)ê¹Œì§€ê°€ 3ë“±ê¸‰ì´ ëœë‹¤.
[EBSI ì°¸ê³ ](https://www.ebsi.co.kr/ebs/ent/enta/retrieveEntNewsView.ebs?bbsCd=B011&datNo=142017)



## ğŸ“— ì°¸ê³ í•´ë³¼ë§Œí•œ Reference

- [Nomadamas ì‹¤í—˜ê¸°ë¡](https://github.com/NomaDamas/KICE_slayer_AI_Korean?tab=readme-ov-file#5-%ED%98%95%EC%8B%9D-%EC%A7%80%EC%A0%95-%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8)

## ğŸ“° Notice

- ì €ì‘ê¶Œ ë¬¸ì œê°€ ìˆì„ìˆ˜ ìˆì–´ ìˆ˜ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì€ ê³µê°œí•˜ì§€ ì•Šì„ ì˜ˆì •ì…ë‹ˆë‹¤. í‰ê°€ ë°ì´í„°ëŠ” 15ìˆ˜ëŠ¥ ~ 24ìˆ˜ëŠ¥ì…ë‹ˆë‹¤.
- í‰ê°€ì˜ ê³µì •ì„±ì„ ìœ„í•´ì„œ í”„ë¡¬í”„íŠ¸ëŠ” ê³µê°œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!
- ì¶”í›„ ìˆ˜ëŠ¥ ë‹¹ì¼ ì œì¶œí•´ì£¼ì‹  ëª¨ë¸ë“¤ì„ ì „ë¶€ ë°˜ì˜í•  êµ­ì˜ìˆ˜ì‚¬ê³¼ ëª¨ë‘ ë¦¬ë”ë³´ë“œì—ì„œ ì—…ë°ì´íŠ¸ ì˜ˆì •ì…ë‹ˆë‹¤.


## ğŸ“¬ ë¬¸ì˜í•˜ê¸°

- ê¶ê¸ˆí•œ ì ì´ë‚˜ ì˜¤ë¥˜, ì§€ì›ì´ í•„ìš”í•˜ë‹¤ë©´ ì–¸ì œë“ ì§€ ì—°ë½í•´ ì£¼ì„¸ìš”:

- ì´ë©”ì¼: developerminsing@gmail.com

**ë‹¤ìŒ KO-SAT Slayer Champion**ì´ ë  ì¤€ë¹„ê°€ ë˜ì…¨ë‚˜ìš”? ğŸ’ª

